{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Milestone03_ZhuoyuPeng.ipynb","provenance":[{"file_id":"1BQIcvqVpzMeZu_mkK_MdWbcovuNTaYrb","timestamp":1598334899199}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"68oMJGQfLvgo","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vspvAd3BLvgr","colab_type":"text"},"source":["### 1.Split prepared data from Milestone 1 into training and testing"]},{"cell_type":"markdown","metadata":{"id":"Vfl49xi4Lvgs","colab_type":"text"},"source":["#### Read and merge data\n","\n","I used Google labs, so below codes are for reading the files from Google drive."]},{"cell_type":"code","metadata":{"id":"6rMqXpIbMTTt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"ok","timestamp":1598577678701,"user_tz":420,"elapsed":23316,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"9bdb8971-f9d6-427f-e5a7-555473fd3ef2"},"source":["# Install a Drive FUSE wrapper.\n","# https://github.com/astrada/google-drive-ocamlfuse\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null \n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse"],"execution_count":null,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 144556 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.22-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.22-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.22-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-f2sI-_vMc3Y","colab_type":"code","colab":{}},"source":["# Generate auth tokens for Colab\n","\n","from google.colab import auth \n","auth.authenticate_user()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UErjYPmGMfmR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598577727716,"user_tz":420,"elapsed":72317,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"6179097b-8c4f-4e1d-8704-19a7e4a1de42"},"source":["# Generate creds for the Drive FUSE library.\n","\n","from oauth2client.client import GoogleCredentials \n","creds = GoogleCredentials.get_application_default()\n","import getpass \n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass() \n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0_vefK6GMnQj","colab_type":"code","colab":{}},"source":["# Create a directory and mount Google Drive using that directory.\n","\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"asUk1ZsSM7LD","colab_type":"code","colab":{}},"source":["# print ('Files in Drive:')\n","# !ls drive/Colab_Notebooks/M03"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJQxgsmzLvgs","colab_type":"code","colab":{}},"source":["#read two data files\n","df = pd.read_excel('drive/Colab_Notebooks/M03/secom.xlsx',header= None)\n","label = pd.read_excel('drive/Colab_Notebooks/M03/secom_labels.xlsx', header = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgQD80PJLvgu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":330},"executionInfo":{"status":"ok","timestamp":1598577740225,"user_tz":420,"elapsed":84799,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"057f662a-4e34-4e28-b74e-d838b562a163"},"source":["#merge two data sets\n","label.columns = ['class', 'time']\n","df = df.add_prefix('sensor_')\n","data = pd.concat([df,label], axis=1)\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sensor_0</th>\n","      <th>sensor_1</th>\n","      <th>sensor_2</th>\n","      <th>sensor_3</th>\n","      <th>sensor_4</th>\n","      <th>sensor_5</th>\n","      <th>sensor_6</th>\n","      <th>sensor_7</th>\n","      <th>sensor_8</th>\n","      <th>sensor_9</th>\n","      <th>sensor_10</th>\n","      <th>sensor_11</th>\n","      <th>sensor_12</th>\n","      <th>sensor_13</th>\n","      <th>sensor_14</th>\n","      <th>sensor_15</th>\n","      <th>sensor_16</th>\n","      <th>sensor_17</th>\n","      <th>sensor_18</th>\n","      <th>sensor_19</th>\n","      <th>sensor_20</th>\n","      <th>sensor_21</th>\n","      <th>sensor_22</th>\n","      <th>sensor_23</th>\n","      <th>sensor_24</th>\n","      <th>sensor_25</th>\n","      <th>sensor_26</th>\n","      <th>sensor_27</th>\n","      <th>sensor_28</th>\n","      <th>sensor_29</th>\n","      <th>sensor_30</th>\n","      <th>sensor_31</th>\n","      <th>sensor_32</th>\n","      <th>sensor_33</th>\n","      <th>sensor_34</th>\n","      <th>sensor_35</th>\n","      <th>sensor_36</th>\n","      <th>sensor_37</th>\n","      <th>sensor_38</th>\n","      <th>sensor_39</th>\n","      <th>...</th>\n","      <th>sensor_552</th>\n","      <th>sensor_553</th>\n","      <th>sensor_554</th>\n","      <th>sensor_555</th>\n","      <th>sensor_556</th>\n","      <th>sensor_557</th>\n","      <th>sensor_558</th>\n","      <th>sensor_559</th>\n","      <th>sensor_560</th>\n","      <th>sensor_561</th>\n","      <th>sensor_562</th>\n","      <th>sensor_563</th>\n","      <th>sensor_564</th>\n","      <th>sensor_565</th>\n","      <th>sensor_566</th>\n","      <th>sensor_567</th>\n","      <th>sensor_568</th>\n","      <th>sensor_569</th>\n","      <th>sensor_570</th>\n","      <th>sensor_571</th>\n","      <th>sensor_572</th>\n","      <th>sensor_573</th>\n","      <th>sensor_574</th>\n","      <th>sensor_575</th>\n","      <th>sensor_576</th>\n","      <th>sensor_577</th>\n","      <th>sensor_578</th>\n","      <th>sensor_579</th>\n","      <th>sensor_580</th>\n","      <th>sensor_581</th>\n","      <th>sensor_582</th>\n","      <th>sensor_583</th>\n","      <th>sensor_584</th>\n","      <th>sensor_585</th>\n","      <th>sensor_586</th>\n","      <th>sensor_587</th>\n","      <th>sensor_588</th>\n","      <th>sensor_589</th>\n","      <th>class</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3030.93</td>\n","      <td>2564.00</td>\n","      <td>2187.7333</td>\n","      <td>1411.1265</td>\n","      <td>1.3602</td>\n","      <td>100.0</td>\n","      <td>97.6133</td>\n","      <td>0.1242</td>\n","      <td>1.5005</td>\n","      <td>0.0162</td>\n","      <td>-0.0034</td>\n","      <td>0.9455</td>\n","      <td>202.4396</td>\n","      <td>0.0</td>\n","      <td>7.9558</td>\n","      <td>414.8710</td>\n","      <td>10.0433</td>\n","      <td>0.9680</td>\n","      <td>192.3963</td>\n","      <td>12.5190</td>\n","      <td>1.4026</td>\n","      <td>-5419.00</td>\n","      <td>2916.50</td>\n","      <td>-4043.75</td>\n","      <td>751.00</td>\n","      <td>0.8955</td>\n","      <td>1.7730</td>\n","      <td>3.0490</td>\n","      <td>64.2333</td>\n","      <td>2.0222</td>\n","      <td>0.1632</td>\n","      <td>3.5191</td>\n","      <td>83.3971</td>\n","      <td>9.5126</td>\n","      <td>50.6170</td>\n","      <td>64.2588</td>\n","      <td>49.3830</td>\n","      <td>66.3141</td>\n","      <td>86.9555</td>\n","      <td>117.5132</td>\n","      <td>...</td>\n","      <td>0.1827</td>\n","      <td>5.7349</td>\n","      <td>0.3363</td>\n","      <td>39.8842</td>\n","      <td>3.2687</td>\n","      <td>1.0297</td>\n","      <td>1.0344</td>\n","      <td>0.4385</td>\n","      <td>0.1039</td>\n","      <td>42.3877</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>533.8500</td>\n","      <td>2.1113</td>\n","      <td>8.95</td>\n","      <td>0.3157</td>\n","      <td>3.0624</td>\n","      <td>0.1026</td>\n","      <td>1.6765</td>\n","      <td>14.9509</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.5005</td>\n","      <td>0.0118</td>\n","      <td>0.0035</td>\n","      <td>2.3630</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>19/07/2008 11:55:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3095.78</td>\n","      <td>2465.14</td>\n","      <td>2230.4222</td>\n","      <td>1463.6606</td>\n","      <td>0.8294</td>\n","      <td>100.0</td>\n","      <td>102.3433</td>\n","      <td>0.1247</td>\n","      <td>1.4966</td>\n","      <td>-0.0005</td>\n","      <td>-0.0148</td>\n","      <td>0.9627</td>\n","      <td>200.5470</td>\n","      <td>0.0</td>\n","      <td>10.1548</td>\n","      <td>414.7347</td>\n","      <td>9.2599</td>\n","      <td>0.9701</td>\n","      <td>191.2872</td>\n","      <td>12.4608</td>\n","      <td>1.3825</td>\n","      <td>-5441.50</td>\n","      <td>2604.25</td>\n","      <td>-3498.75</td>\n","      <td>-1640.25</td>\n","      <td>1.2973</td>\n","      <td>2.0143</td>\n","      <td>7.3900</td>\n","      <td>68.4222</td>\n","      <td>2.2667</td>\n","      <td>0.2102</td>\n","      <td>3.4171</td>\n","      <td>84.9052</td>\n","      <td>9.7997</td>\n","      <td>50.6596</td>\n","      <td>64.2828</td>\n","      <td>49.3404</td>\n","      <td>64.9193</td>\n","      <td>87.5241</td>\n","      <td>118.1188</td>\n","      <td>...</td>\n","      <td>0.2829</td>\n","      <td>7.1196</td>\n","      <td>0.4989</td>\n","      <td>53.1836</td>\n","      <td>3.9139</td>\n","      <td>1.7819</td>\n","      <td>0.9634</td>\n","      <td>0.1745</td>\n","      <td>0.0375</td>\n","      <td>18.1087</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>535.0164</td>\n","      <td>2.4335</td>\n","      <td>5.92</td>\n","      <td>0.2653</td>\n","      <td>2.0111</td>\n","      <td>0.0772</td>\n","      <td>1.1065</td>\n","      <td>10.9003</td>\n","      <td>0.0096</td>\n","      <td>0.0201</td>\n","      <td>0.0060</td>\n","      <td>208.2045</td>\n","      <td>0.5019</td>\n","      <td>0.0223</td>\n","      <td>0.0055</td>\n","      <td>4.4447</td>\n","      <td>0.0096</td>\n","      <td>0.0201</td>\n","      <td>0.0060</td>\n","      <td>208.2045</td>\n","      <td>-1</td>\n","      <td>19/07/2008 12:32:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2932.61</td>\n","      <td>2559.94</td>\n","      <td>2186.4111</td>\n","      <td>1698.0172</td>\n","      <td>1.5102</td>\n","      <td>100.0</td>\n","      <td>95.4878</td>\n","      <td>0.1241</td>\n","      <td>1.4436</td>\n","      <td>0.0041</td>\n","      <td>0.0013</td>\n","      <td>0.9615</td>\n","      <td>202.0179</td>\n","      <td>0.0</td>\n","      <td>9.5157</td>\n","      <td>416.7075</td>\n","      <td>9.3144</td>\n","      <td>0.9674</td>\n","      <td>192.7035</td>\n","      <td>12.5404</td>\n","      <td>1.4123</td>\n","      <td>-5447.75</td>\n","      <td>2701.75</td>\n","      <td>-4047.00</td>\n","      <td>-1916.50</td>\n","      <td>1.3122</td>\n","      <td>2.0295</td>\n","      <td>7.5788</td>\n","      <td>67.1333</td>\n","      <td>2.3333</td>\n","      <td>0.1734</td>\n","      <td>3.5986</td>\n","      <td>84.7569</td>\n","      <td>8.6590</td>\n","      <td>50.1530</td>\n","      <td>64.1114</td>\n","      <td>49.8470</td>\n","      <td>65.8389</td>\n","      <td>84.7327</td>\n","      <td>118.6128</td>\n","      <td>...</td>\n","      <td>0.0857</td>\n","      <td>7.1619</td>\n","      <td>0.3752</td>\n","      <td>23.0713</td>\n","      <td>3.9306</td>\n","      <td>1.1386</td>\n","      <td>1.5021</td>\n","      <td>0.3718</td>\n","      <td>0.1233</td>\n","      <td>24.7524</td>\n","      <td>267.064</td>\n","      <td>0.9032</td>\n","      <td>1.10</td>\n","      <td>0.6219</td>\n","      <td>0.4122</td>\n","      <td>0.2562</td>\n","      <td>0.4119</td>\n","      <td>68.8489</td>\n","      <td>535.0245</td>\n","      <td>2.0293</td>\n","      <td>11.21</td>\n","      <td>0.1882</td>\n","      <td>4.0923</td>\n","      <td>0.0640</td>\n","      <td>2.0952</td>\n","      <td>9.2721</td>\n","      <td>0.0584</td>\n","      <td>0.0484</td>\n","      <td>0.0148</td>\n","      <td>82.8602</td>\n","      <td>0.4958</td>\n","      <td>0.0157</td>\n","      <td>0.0039</td>\n","      <td>3.1745</td>\n","      <td>0.0584</td>\n","      <td>0.0484</td>\n","      <td>0.0148</td>\n","      <td>82.8602</td>\n","      <td>1</td>\n","      <td>19/07/2008 13:17:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2988.72</td>\n","      <td>2479.90</td>\n","      <td>2199.0333</td>\n","      <td>909.7926</td>\n","      <td>1.3204</td>\n","      <td>100.0</td>\n","      <td>104.2367</td>\n","      <td>0.1217</td>\n","      <td>1.4882</td>\n","      <td>-0.0124</td>\n","      <td>-0.0033</td>\n","      <td>0.9629</td>\n","      <td>201.8482</td>\n","      <td>0.0</td>\n","      <td>9.6052</td>\n","      <td>422.2894</td>\n","      <td>9.6924</td>\n","      <td>0.9687</td>\n","      <td>192.1557</td>\n","      <td>12.4782</td>\n","      <td>1.4011</td>\n","      <td>-5468.25</td>\n","      <td>2648.25</td>\n","      <td>-4515.00</td>\n","      <td>-1657.25</td>\n","      <td>1.3137</td>\n","      <td>2.0038</td>\n","      <td>7.3145</td>\n","      <td>62.9333</td>\n","      <td>2.6444</td>\n","      <td>0.2071</td>\n","      <td>3.3813</td>\n","      <td>84.9105</td>\n","      <td>8.6789</td>\n","      <td>50.5100</td>\n","      <td>64.1125</td>\n","      <td>49.4900</td>\n","      <td>65.1951</td>\n","      <td>86.6867</td>\n","      <td>117.0442</td>\n","      <td>...</td>\n","      <td>0.6812</td>\n","      <td>56.9303</td>\n","      <td>17.4781</td>\n","      <td>161.4081</td>\n","      <td>35.3198</td>\n","      <td>54.2917</td>\n","      <td>1.1613</td>\n","      <td>0.7288</td>\n","      <td>0.2710</td>\n","      <td>62.7572</td>\n","      <td>268.228</td>\n","      <td>0.6511</td>\n","      <td>7.32</td>\n","      <td>0.1630</td>\n","      <td>3.5611</td>\n","      <td>0.0670</td>\n","      <td>2.7290</td>\n","      <td>25.0363</td>\n","      <td>530.5682</td>\n","      <td>2.0253</td>\n","      <td>9.33</td>\n","      <td>0.1738</td>\n","      <td>2.8971</td>\n","      <td>0.0525</td>\n","      <td>1.7585</td>\n","      <td>8.5831</td>\n","      <td>0.0202</td>\n","      <td>0.0149</td>\n","      <td>0.0044</td>\n","      <td>73.8432</td>\n","      <td>0.4990</td>\n","      <td>0.0103</td>\n","      <td>0.0025</td>\n","      <td>2.0544</td>\n","      <td>0.0202</td>\n","      <td>0.0149</td>\n","      <td>0.0044</td>\n","      <td>73.8432</td>\n","      <td>-1</td>\n","      <td>19/07/2008 14:43:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3032.24</td>\n","      <td>2502.87</td>\n","      <td>2233.3667</td>\n","      <td>1326.5200</td>\n","      <td>1.5334</td>\n","      <td>100.0</td>\n","      <td>100.3967</td>\n","      <td>0.1235</td>\n","      <td>1.5031</td>\n","      <td>-0.0031</td>\n","      <td>-0.0072</td>\n","      <td>0.9569</td>\n","      <td>201.9424</td>\n","      <td>0.0</td>\n","      <td>10.5661</td>\n","      <td>420.5925</td>\n","      <td>10.3387</td>\n","      <td>0.9735</td>\n","      <td>191.6037</td>\n","      <td>12.4735</td>\n","      <td>1.3888</td>\n","      <td>-5476.25</td>\n","      <td>2635.25</td>\n","      <td>-3987.50</td>\n","      <td>117.00</td>\n","      <td>1.2887</td>\n","      <td>1.9912</td>\n","      <td>7.2748</td>\n","      <td>62.8333</td>\n","      <td>3.1556</td>\n","      <td>0.2696</td>\n","      <td>3.2728</td>\n","      <td>86.3269</td>\n","      <td>8.7677</td>\n","      <td>50.2480</td>\n","      <td>64.1511</td>\n","      <td>49.7520</td>\n","      <td>66.1542</td>\n","      <td>86.1468</td>\n","      <td>121.4364</td>\n","      <td>...</td>\n","      <td>0.4287</td>\n","      <td>9.7608</td>\n","      <td>0.8311</td>\n","      <td>70.9706</td>\n","      <td>4.9086</td>\n","      <td>2.5014</td>\n","      <td>0.9778</td>\n","      <td>0.2156</td>\n","      <td>0.0461</td>\n","      <td>22.0500</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>532.0155</td>\n","      <td>2.0275</td>\n","      <td>8.83</td>\n","      <td>0.2224</td>\n","      <td>3.1776</td>\n","      <td>0.0706</td>\n","      <td>1.6597</td>\n","      <td>10.9698</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.4800</td>\n","      <td>0.4766</td>\n","      <td>0.1045</td>\n","      <td>99.3032</td>\n","      <td>0.0202</td>\n","      <td>0.0149</td>\n","      <td>0.0044</td>\n","      <td>73.8432</td>\n","      <td>-1</td>\n","      <td>19/07/2008 15:22:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 592 columns</p>\n","</div>"],"text/plain":["   sensor_0  sensor_1   sensor_2  ...  sensor_589  class                 time\n","0   3030.93   2564.00  2187.7333  ...         NaN     -1  19/07/2008 11:55:00\n","1   3095.78   2465.14  2230.4222  ...    208.2045     -1  19/07/2008 12:32:00\n","2   2932.61   2559.94  2186.4111  ...     82.8602      1  19/07/2008 13:17:00\n","3   2988.72   2479.90  2199.0333  ...     73.8432     -1  19/07/2008 14:43:00\n","4   3032.24   2502.87  2233.3667  ...     73.8432     -1  19/07/2008 15:22:00\n","\n","[5 rows x 592 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"j0yi8sFPLvgy","colab_type":"text"},"source":["#### Clean and prepare data"]},{"cell_type":"markdown","metadata":{"id":"drm2FwKILvgy","colab_type":"text"},"source":["Clean dataset, impute missing values. \n","\n","First, check whether target attribute has NaN, if yes, drop NaN in class, since imputing class label is not that reasonable."]},{"cell_type":"code","metadata":{"id":"z4m4ebMZLvgy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598577740225,"user_tz":420,"elapsed":84784,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"1f27562f-5ec1-4fdf-e882-4eeb3097b26e"},"source":["print(sum(data['class'].isnull()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sgdnA3nHLvg0","colab_type":"text"},"source":["Target varibles have no NaN. \n","\n","Check whether time_stamp has NaN. Again, this one is not reasonable to impute values. "]},{"cell_type":"code","metadata":{"id":"p968vSa_Lvg1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598577740226,"user_tz":420,"elapsed":84774,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"47592cc8-6873-462c-eaeb-353b824ef9f7"},"source":["print(sum(data['time'].isnull()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EabJJrAtLvg3","colab_type":"text"},"source":["No missing values in time_stamp.\n","\n","Next step, we can loop through each column, and impute missing values with median."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"JAQyWqxtLvg3","colab_type":"code","colab":{}},"source":["for i in range(0,590):\n","    name = 'sensor_'+str(i) \n","    HasNan =data[name].isnull()\n","    if sum(HasNan) > 0:\n","        data.loc[HasNan, name] =  np.mean(data[name])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lBjG9SW6Lvg5","colab_type":"text"},"source":["Data is cleaned with missing values.\n","\n","There is no more missing values.  Let's take care of time_stamp data. Time_stamp data is a little bit messy, has different kind of format"]},{"cell_type":"code","metadata":{"id":"igNgoSJkLvg6","colab_type":"code","colab":{}},"source":["#convert time_stamp to datetime format\n","data['time'] = pd.to_datetime(data['time'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xVoi9swPLvg7","colab_type":"text"},"source":["Now, the data is cleaned and next, normalizing the dataset."]},{"cell_type":"code","metadata":{"id":"N9uYXJ-bPiI7","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","data_notime = data.drop(columns='time') #exclude time when normalizing\n","scaler = MinMaxScaler()\n","nor = scaler.fit_transform(data_notime)\n","data_notime_nor = pd.DataFrame(nor, columns = data_notime.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-m7bGyCQA3h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"ok","timestamp":1598577741992,"user_tz":420,"elapsed":86513,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"a6374596-27a3-4004-b7d2-d78cfc18b6bb"},"source":["data_notime_nor.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sensor_0</th>\n","      <th>sensor_1</th>\n","      <th>sensor_2</th>\n","      <th>sensor_3</th>\n","      <th>sensor_4</th>\n","      <th>sensor_5</th>\n","      <th>sensor_6</th>\n","      <th>sensor_7</th>\n","      <th>sensor_8</th>\n","      <th>sensor_9</th>\n","      <th>sensor_10</th>\n","      <th>sensor_11</th>\n","      <th>sensor_12</th>\n","      <th>sensor_13</th>\n","      <th>sensor_14</th>\n","      <th>sensor_15</th>\n","      <th>sensor_16</th>\n","      <th>sensor_17</th>\n","      <th>sensor_18</th>\n","      <th>sensor_19</th>\n","      <th>sensor_20</th>\n","      <th>sensor_21</th>\n","      <th>sensor_22</th>\n","      <th>sensor_23</th>\n","      <th>sensor_24</th>\n","      <th>sensor_25</th>\n","      <th>sensor_26</th>\n","      <th>sensor_27</th>\n","      <th>sensor_28</th>\n","      <th>sensor_29</th>\n","      <th>sensor_30</th>\n","      <th>sensor_31</th>\n","      <th>sensor_32</th>\n","      <th>sensor_33</th>\n","      <th>sensor_34</th>\n","      <th>sensor_35</th>\n","      <th>sensor_36</th>\n","      <th>sensor_37</th>\n","      <th>sensor_38</th>\n","      <th>sensor_39</th>\n","      <th>...</th>\n","      <th>sensor_551</th>\n","      <th>sensor_552</th>\n","      <th>sensor_553</th>\n","      <th>sensor_554</th>\n","      <th>sensor_555</th>\n","      <th>sensor_556</th>\n","      <th>sensor_557</th>\n","      <th>sensor_558</th>\n","      <th>sensor_559</th>\n","      <th>sensor_560</th>\n","      <th>sensor_561</th>\n","      <th>sensor_562</th>\n","      <th>sensor_563</th>\n","      <th>sensor_564</th>\n","      <th>sensor_565</th>\n","      <th>sensor_566</th>\n","      <th>sensor_567</th>\n","      <th>sensor_568</th>\n","      <th>sensor_569</th>\n","      <th>sensor_570</th>\n","      <th>sensor_571</th>\n","      <th>sensor_572</th>\n","      <th>sensor_573</th>\n","      <th>sensor_574</th>\n","      <th>sensor_575</th>\n","      <th>sensor_576</th>\n","      <th>sensor_577</th>\n","      <th>sensor_578</th>\n","      <th>sensor_579</th>\n","      <th>sensor_580</th>\n","      <th>sensor_581</th>\n","      <th>sensor_582</th>\n","      <th>sensor_583</th>\n","      <th>sensor_584</th>\n","      <th>sensor_585</th>\n","      <th>sensor_586</th>\n","      <th>sensor_587</th>\n","      <th>sensor_588</th>\n","      <th>sensor_589</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.469231</td>\n","      <td>0.589292</td>\n","      <td>0.499096</td>\n","      <td>0.379841</td>\n","      <td>0.000609</td>\n","      <td>0.0</td>\n","      <td>0.328562</td>\n","      <td>0.965785</td>\n","      <td>0.665019</td>\n","      <td>0.542479</td>\n","      <td>0.358362</td>\n","      <td>0.880692</td>\n","      <td>0.226185</td>\n","      <td>0.0</td>\n","      <td>0.329909</td>\n","      <td>0.165668</td>\n","      <td>0.056644</td>\n","      <td>0.958559</td>\n","      <td>0.500188</td>\n","      <td>0.848739</td>\n","      <td>0.814395</td>\n","      <td>0.242124</td>\n","      <td>0.797675</td>\n","      <td>0.481224</td>\n","      <td>0.538057</td>\n","      <td>0.647599</td>\n","      <td>0.863698</td>\n","      <td>0.398104</td>\n","      <td>0.261259</td>\n","      <td>0.476550</td>\n","      <td>0.514343</td>\n","      <td>0.529986</td>\n","      <td>0.009554</td>\n","      <td>0.121293</td>\n","      <td>0.078721</td>\n","      <td>0.019008</td>\n","      <td>0.921279</td>\n","      <td>0.458921</td>\n","      <td>0.603022</td>\n","      <td>0.267583</td>\n","      <td>...</td>\n","      <td>0.016832</td>\n","      <td>0.060752</td>\n","      <td>0.054464</td>\n","      <td>0.016315</td>\n","      <td>0.117357</td>\n","      <td>0.052390</td>\n","      <td>0.015983</td>\n","      <td>0.229765</td>\n","      <td>0.367205</td>\n","      <td>0.201402</td>\n","      <td>0.374432</td>\n","      <td>0.295779</td>\n","      <td>0.377041</td>\n","      <td>0.173204</td>\n","      <td>0.184777</td>\n","      <td>0.161644</td>\n","      <td>0.179466</td>\n","      <td>0.168219</td>\n","      <td>0.219091</td>\n","      <td>0.795609</td>\n","      <td>0.642926</td>\n","      <td>0.011995</td>\n","      <td>0.116901</td>\n","      <td>0.011971</td>\n","      <td>0.150986</td>\n","      <td>0.011285</td>\n","      <td>0.112244</td>\n","      <td>0.321759</td>\n","      <td>0.177698</td>\n","      <td>0.159274</td>\n","      <td>0.132828</td>\n","      <td>0.709375</td>\n","      <td>0.012325</td>\n","      <td>0.017510</td>\n","      <td>0.011880</td>\n","      <td>0.320455</td>\n","      <td>0.173076</td>\n","      <td>0.155193</td>\n","      <td>0.135182</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.575003</td>\n","      <td>0.445535</td>\n","      <td>0.666763</td>\n","      <td>0.393982</td>\n","      <td>0.000133</td>\n","      <td>0.0</td>\n","      <td>0.428942</td>\n","      <td>0.969673</td>\n","      <td>0.656639</td>\n","      <td>0.412315</td>\n","      <td>0.228669</td>\n","      <td>0.932908</td>\n","      <td>0.205145</td>\n","      <td>0.0</td>\n","      <td>0.457039</td>\n","      <td>0.165391</td>\n","      <td>0.048683</td>\n","      <td>0.963740</td>\n","      <td>0.476296</td>\n","      <td>0.830040</td>\n","      <td>0.740957</td>\n","      <td>0.238978</td>\n","      <td>0.712274</td>\n","      <td>0.525355</td>\n","      <td>0.455345</td>\n","      <td>0.938169</td>\n","      <td>0.981245</td>\n","      <td>0.964903</td>\n","      <td>0.487686</td>\n","      <td>0.562509</td>\n","      <td>0.701594</td>\n","      <td>0.492686</td>\n","      <td>0.076817</td>\n","      <td>0.139530</td>\n","      <td>0.083009</td>\n","      <td>0.019793</td>\n","      <td>0.916991</td>\n","      <td>0.000000</td>\n","      <td>0.757277</td>\n","      <td>0.295521</td>\n","      <td>...</td>\n","      <td>0.030859</td>\n","      <td>0.097870</td>\n","      <td>0.080038</td>\n","      <td>0.025645</td>\n","      <td>0.161878</td>\n","      <td>0.071466</td>\n","      <td>0.029880</td>\n","      <td>0.115285</td>\n","      <td>0.104204</td>\n","      <td>0.046262</td>\n","      <td>0.115808</td>\n","      <td>0.295779</td>\n","      <td>0.377041</td>\n","      <td>0.173204</td>\n","      <td>0.184777</td>\n","      <td>0.161644</td>\n","      <td>0.179466</td>\n","      <td>0.168219</td>\n","      <td>0.219091</td>\n","      <td>0.799892</td>\n","      <td>0.826067</td>\n","      <td>0.005277</td>\n","      <td>0.093239</td>\n","      <td>0.005750</td>\n","      <td>0.102807</td>\n","      <td>0.004934</td>\n","      <td>0.068396</td>\n","      <td>0.221387</td>\n","      <td>0.220339</td>\n","      <td>0.181159</td>\n","      <td>0.282386</td>\n","      <td>0.753125</td>\n","      <td>0.034637</td>\n","      <td>0.036965</td>\n","      <td>0.033099</td>\n","      <td>0.221387</td>\n","      <td>0.220339</td>\n","      <td>0.181159</td>\n","      <td>0.282386</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.308868</td>\n","      <td>0.583388</td>\n","      <td>0.493903</td>\n","      <td>0.457065</td>\n","      <td>0.000744</td>\n","      <td>0.0</td>\n","      <td>0.283455</td>\n","      <td>0.965008</td>\n","      <td>0.542759</td>\n","      <td>0.448168</td>\n","      <td>0.411832</td>\n","      <td>0.929265</td>\n","      <td>0.221497</td>\n","      <td>0.0</td>\n","      <td>0.420091</td>\n","      <td>0.169405</td>\n","      <td>0.049237</td>\n","      <td>0.957079</td>\n","      <td>0.506806</td>\n","      <td>0.855614</td>\n","      <td>0.849836</td>\n","      <td>0.238104</td>\n","      <td>0.738940</td>\n","      <td>0.480961</td>\n","      <td>0.445790</td>\n","      <td>0.948944</td>\n","      <td>0.988650</td>\n","      <td>0.989554</td>\n","      <td>0.418016</td>\n","      <td>0.585923</td>\n","      <td>0.554980</td>\n","      <td>0.559058</td>\n","      <td>0.070202</td>\n","      <td>0.067069</td>\n","      <td>0.032024</td>\n","      <td>0.014189</td>\n","      <td>0.967976</td>\n","      <td>0.302570</td>\n","      <td>0.000000</td>\n","      <td>0.318310</td>\n","      <td>...</td>\n","      <td>0.018618</td>\n","      <td>0.024819</td>\n","      <td>0.080819</td>\n","      <td>0.018547</td>\n","      <td>0.061075</td>\n","      <td>0.071960</td>\n","      <td>0.017995</td>\n","      <td>0.983876</td>\n","      <td>0.300757</td>\n","      <td>0.246729</td>\n","      <td>0.186578</td>\n","      <td>0.358488</td>\n","      <td>0.601972</td>\n","      <td>0.004113</td>\n","      <td>0.899070</td>\n","      <td>0.000000</td>\n","      <td>0.869764</td>\n","      <td>0.003337</td>\n","      <td>0.804376</td>\n","      <td>0.799922</td>\n","      <td>0.596317</td>\n","      <td>0.017006</td>\n","      <td>0.057042</td>\n","      <td>0.018066</td>\n","      <td>0.077769</td>\n","      <td>0.015949</td>\n","      <td>0.050771</td>\n","      <td>0.629073</td>\n","      <td>0.589309</td>\n","      <td>0.500000</td>\n","      <td>0.112383</td>\n","      <td>0.562500</td>\n","      <td>0.020612</td>\n","      <td>0.021401</td>\n","      <td>0.020152</td>\n","      <td>0.629073</td>\n","      <td>0.589309</td>\n","      <td>0.500000</td>\n","      <td>0.112383</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.400385</td>\n","      <td>0.466998</td>\n","      <td>0.543479</td>\n","      <td>0.244894</td>\n","      <td>0.000574</td>\n","      <td>0.0</td>\n","      <td>0.469123</td>\n","      <td>0.946345</td>\n","      <td>0.638590</td>\n","      <td>0.319564</td>\n","      <td>0.359499</td>\n","      <td>0.933515</td>\n","      <td>0.219610</td>\n","      <td>0.0</td>\n","      <td>0.425265</td>\n","      <td>0.180762</td>\n","      <td>0.053078</td>\n","      <td>0.960286</td>\n","      <td>0.495005</td>\n","      <td>0.835631</td>\n","      <td>0.808915</td>\n","      <td>0.235237</td>\n","      <td>0.724308</td>\n","      <td>0.443066</td>\n","      <td>0.454757</td>\n","      <td>0.950029</td>\n","      <td>0.976130</td>\n","      <td>0.955045</td>\n","      <td>0.190989</td>\n","      <td>0.695296</td>\n","      <td>0.689243</td>\n","      <td>0.479595</td>\n","      <td>0.077053</td>\n","      <td>0.068333</td>\n","      <td>0.067953</td>\n","      <td>0.014225</td>\n","      <td>0.932047</td>\n","      <td>0.090745</td>\n","      <td>0.530100</td>\n","      <td>0.245947</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.245416</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.524168</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.434376</td>\n","      <td>0.656406</td>\n","      <td>0.591822</td>\n","      <td>0.591411</td>\n","      <td>0.375329</td>\n","      <td>0.348325</td>\n","      <td>0.200886</td>\n","      <td>0.210858</td>\n","      <td>0.231504</td>\n","      <td>0.203801</td>\n","      <td>0.190569</td>\n","      <td>0.267141</td>\n","      <td>0.783557</td>\n","      <td>0.594043</td>\n","      <td>0.012838</td>\n","      <td>0.050282</td>\n","      <td>0.010993</td>\n","      <td>0.055956</td>\n","      <td>0.012198</td>\n","      <td>0.043312</td>\n","      <td>0.309942</td>\n","      <td>0.152542</td>\n","      <td>0.123188</td>\n","      <td>0.100153</td>\n","      <td>0.662500</td>\n","      <td>0.009137</td>\n","      <td>0.007782</td>\n","      <td>0.008734</td>\n","      <td>0.309942</td>\n","      <td>0.152542</td>\n","      <td>0.123188</td>\n","      <td>0.100153</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.471367</td>\n","      <td>0.500400</td>\n","      <td>0.678327</td>\n","      <td>0.357067</td>\n","      <td>0.000765</td>\n","      <td>0.0</td>\n","      <td>0.387631</td>\n","      <td>0.960342</td>\n","      <td>0.670606</td>\n","      <td>0.392050</td>\n","      <td>0.315131</td>\n","      <td>0.915301</td>\n","      <td>0.220658</td>\n","      <td>0.0</td>\n","      <td>0.480818</td>\n","      <td>0.177310</td>\n","      <td>0.059646</td>\n","      <td>0.972126</td>\n","      <td>0.483114</td>\n","      <td>0.834120</td>\n","      <td>0.763975</td>\n","      <td>0.234118</td>\n","      <td>0.720752</td>\n","      <td>0.485779</td>\n","      <td>0.516127</td>\n","      <td>0.931950</td>\n","      <td>0.969992</td>\n","      <td>0.949862</td>\n","      <td>0.185584</td>\n","      <td>0.875018</td>\n","      <td>0.938247</td>\n","      <td>0.439918</td>\n","      <td>0.140226</td>\n","      <td>0.073974</td>\n","      <td>0.041585</td>\n","      <td>0.015487</td>\n","      <td>0.958415</td>\n","      <td>0.406311</td>\n","      <td>0.383630</td>\n","      <td>0.448568</td>\n","      <td>...</td>\n","      <td>0.047437</td>\n","      <td>0.151880</td>\n","      <td>0.128819</td>\n","      <td>0.044709</td>\n","      <td>0.221421</td>\n","      <td>0.100875</td>\n","      <td>0.043172</td>\n","      <td>0.138504</td>\n","      <td>0.145148</td>\n","      <td>0.066355</td>\n","      <td>0.157791</td>\n","      <td>0.295779</td>\n","      <td>0.377041</td>\n","      <td>0.173204</td>\n","      <td>0.184777</td>\n","      <td>0.161644</td>\n","      <td>0.179466</td>\n","      <td>0.168219</td>\n","      <td>0.219091</td>\n","      <td>0.788872</td>\n","      <td>0.595294</td>\n","      <td>0.011729</td>\n","      <td>0.073099</td>\n","      <td>0.012653</td>\n","      <td>0.090288</td>\n","      <td>0.011097</td>\n","      <td>0.069148</td>\n","      <td>0.321759</td>\n","      <td>0.177698</td>\n","      <td>0.159274</td>\n","      <td>0.132828</td>\n","      <td>0.068750</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.309942</td>\n","      <td>0.152542</td>\n","      <td>0.123188</td>\n","      <td>0.100153</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 591 columns</p>\n","</div>"],"text/plain":["   sensor_0  sensor_1  sensor_2  ...  sensor_588  sensor_589  class\n","0  0.469231  0.589292  0.499096  ...    0.155193    0.135182    0.0\n","1  0.575003  0.445535  0.666763  ...    0.181159    0.282386    0.0\n","2  0.308868  0.583388  0.493903  ...    0.500000    0.112383    1.0\n","3  0.400385  0.466998  0.543479  ...    0.123188    0.100153    0.0\n","4  0.471367  0.500400  0.678327  ...    0.123188    0.100153    0.0\n","\n","[5 rows x 591 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"aVlYY4B6Lvg8","colab_type":"text"},"source":["#### Handle class imbalance problem"]},{"cell_type":"code","metadata":{"id":"DLEZRHx0Lvg8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598577741993,"user_tz":420,"elapsed":86507,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"3fdcf7aa-437a-4968-b3f0-c35844110342"},"source":["# import SMOTE package\n","from collections import Counter\n","from imblearn.over_sampling import SMOTE \n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JtR9CciXLvg-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598577742386,"user_tz":420,"elapsed":86893,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"107e549e-7187-46ff-c17c-06380a95d554"},"source":["# handle imbalance data set using SMOTE\n","X = data_notime_nor.iloc[:,:-2]\n","y= data_notime_nor['class']\n","\n","#split data first, then apply SMOTE\n","X_train, X_test, y_train, y_test = train_test_split (X,y, random_state =0)\n","\n","print('Original dataset shape {}'.format(Counter(y)))\n","sm = SMOTE(random_state=0)\n","X_res, y_res = sm.fit_sample(X_train, y_train)\n","print('Resampled dataset shape {}'.format(Counter(y_res)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original dataset shape Counter({0.0: 1463, 1.0: 104})\n","Resampled dataset shape Counter({0.0: 1092, 1.0: 1092})\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"NQg7JDQ8S8-x","colab_type":"text"},"source":["### 1. Build a simple neural network and DNN model (Code from L08)"]},{"cell_type":"code","metadata":{"id":"suMTDXUQO4Wd","colab_type":"code","colab":{}},"source":["from random import random\n","from math import exp\n","from random import randrange\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","    dataset_split = list()\n","    dataset_copy = list(dataset)\n","    fold_size = int(len(dataset) / n_folds)\n","    for i in range(n_folds):\n","        fold = list()\n","        while len(fold) < fold_size:\n","            index = randrange(len(dataset_copy))\n","            fold.append(dataset_copy.pop(index))\n","        dataset_split.append(fold)\n","    return dataset_split\n","\n","def initialize_network(n_inputs, n_hidden, n_outputs):\n","    network = list()\n","    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n","    network.append(hidden_layer)\n","    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n","    network.append(output_layer)\n","    return network  \n","\n","\n","# Calculate neuron activation for an input\n","def activate(weights, inputs):\n","    activation = weights[-1]\n","    for i in range(len(weights)-1):\n","#         print(weights[i])\n","#         print (inputs[i])\n","#         print(type(weights[i]), type( inputs[i]))\n","        activation += weights[i] * inputs[i]\n","        \n","    return activation\n","\n","# Transfer neuron activation (activation function)\n","def transfer(activation):\n","    return 1.0 / (1.0 + exp(-activation))\n","\n","# Forward propagate input to a network output\n","def forward_propagate(network, row):\n","#     print('row:', row)\n","    inputs = row\n","    for layer in network:\n","        new_inputs = []\n","        for neuron in layer:\n","            activation = activate(neuron['weights'], inputs)\n","            neuron['output'] = transfer(activation)\n","            new_inputs.append(neuron['output'])\n","        inputs = new_inputs\n","#     print(inputs)\n","    return inputs\n","\n","# Calculate the derivative of an neuron output\n","def transfer_derivative(output):\n","    return output * (1.0 - output)\n"," \n","# Backpropagate error and store in neurons\n","def backward_propagate_error(network, expected):\n","    for i in reversed(range(len(network))):\n","#         print('network', network)\n","        layer = network[i]\n","#         print ('layer', layer)\n","        errors = list()\n","        if i != len(network)-1:\n","#             print(len(network))\n","            for j in range(len(layer)):\n","                error = 0.0\n","                for neuron in network[i + 1]:\n","#                     print('network', network)\n","#                     print(\"neuron\",neuron)\n","                    error += (neuron['weights'][j] * neuron['delta'])\n","                errors.append(error)\n","        else:\n","            for j in range(len(layer)):\n","                neuron = layer[j]\n","                errors.append(expected[j] - neuron['output'])\n","                \n","        for j in range(len(layer)):\n","#             print(layer)\n","            neuron = layer[j]\n","            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n","\n","# Update network weights with error\n","def update_weights(network, row, l_rate):\n","    for i in range(len(network)):\n","        inputs = row[:-1]\n","        if i != 0:\n","            inputs = [neuron['output'] for neuron in network[i - 1]]\n","        for neuron in network[i]:\n","            for j in range(len(inputs)):\n","                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n","            neuron['weights'][-1] += l_rate * neuron['delta']\n"," \n","# \n","def train_network(network, train, l_rate, n_epoch, n_outputs):\n","    for epoch in range(n_epoch):\n","        sum_error = 0\n","        for row in train:\n","            outputs = forward_propagate(network, row)\n","            expected = [0 for i in range(n_outputs)]\n","            expected[int(row[-1])] = 1\n","            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n","            backward_propagate_error(network, expected)\n","            update_weights(network, row, l_rate)\n","        print('>epoch=%d, lrate=%.4f, error=%.3f' % (epoch, l_rate, sum_error))\n","  \n","# Backpropagation Algorithm With Stochastic Gradient Descent\n","def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n","    n_inputs = len(train[0]) - 1\n","    n_outputs = len(set([row[-1] for row in train]))\n","    \n","    network = initialize_network(n_inputs, n_hidden, n_outputs)\n","    train_network(network, train, l_rate, n_epoch, n_outputs)\n","    predictions = list()\n","    for row in test:\n","        prediction = predict(network, row)\n","        predictions.append(prediction)\n","    return(predictions)\n","\n","# Make a prediction with a network\n","def predict(network, row):\n","    outputs = forward_propagate(network, row)\n","    return outputs.index(max(outputs))\n","\n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","    correct = 0\n","    for i in range(len(actual)):\n","        if actual[i] == predicted[i]:\n","            correct += 1\n","    return correct / float(len(actual)) * 100.0\n","\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","    folds = cross_validation_split(dataset, n_folds)\n","    scores = list()\n","    for fold in folds:\n","        train_set = list(folds)\n","        train_set.remove(fold)\n","        train_set = sum(train_set, [])\n","        test_set = list()\n","        for row in fold:\n","            row_copy = list(row)\n","            test_set.append(row_copy)\n","            row_copy[-1] = None\n","        predicted = algorithm(train_set, test_set, *args)\n","        actual = [row[-1] for row in fold]\n","        accuracy = accuracy_metric(actual, predicted)\n","        scores.append(accuracy)\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KyG71tVFQta5","colab_type":"code","colab":{}},"source":["data_nor = data_notime_nor.values.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjUzAwOCw_RM","colab_type":"text"},"source":["### 1. Build a simple neural network"]},{"cell_type":"code","metadata":{"id":"iQ998o86T0vU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"status":"ok","timestamp":1598577747176,"user_tz":420,"elapsed":91663,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"360f2a3e-f611-4bc5-93d5-e4a909b8b66c"},"source":["# evaluate algorithm with a simple model with 1 hidden layers\n","n_folds = 5\n","l_rate = 0.001\n","n_epoch = 5\n","n_hidden = 1\n","scores = evaluate_algorithm(data_nor, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n","print('Scores: %s' % scores)\n","print('Mean Accuracy: %.3f%%' % (sum(scores)/(len(scores))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[">epoch=0, lrate=0.001, error=874.057\n",">epoch=1, lrate=0.001, error=758.691\n",">epoch=2, lrate=0.001, error=638.182\n",">epoch=3, lrate=0.001, error=525.967\n",">epoch=4, lrate=0.001, error=433.878\n",">epoch=0, lrate=0.001, error=483.942\n",">epoch=1, lrate=0.001, error=400.968\n",">epoch=2, lrate=0.001, error=342.445\n",">epoch=3, lrate=0.001, error=301.210\n",">epoch=4, lrate=0.001, error=271.691\n",">epoch=0, lrate=0.001, error=513.090\n",">epoch=1, lrate=0.001, error=421.594\n",">epoch=2, lrate=0.001, error=354.217\n",">epoch=3, lrate=0.001, error=306.534\n",">epoch=4, lrate=0.001, error=272.923\n",">epoch=0, lrate=0.001, error=721.498\n",">epoch=1, lrate=0.001, error=612.049\n",">epoch=2, lrate=0.001, error=505.217\n",">epoch=3, lrate=0.001, error=414.900\n",">epoch=4, lrate=0.001, error=346.714\n",">epoch=0, lrate=0.001, error=441.038\n",">epoch=1, lrate=0.001, error=367.637\n",">epoch=2, lrate=0.001, error=315.043\n",">epoch=3, lrate=0.001, error=278.272\n",">epoch=4, lrate=0.001, error=252.436\n","Scores: [94.24920127795528, 92.97124600638978, 92.33226837060703, 93.61022364217251, 93.61022364217251]\n","Mean Accuracy: 93.355%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"exqxR-38UguI"},"source":["In this one hidden layer neural neworks, has high mean accuracy to be 93.42%."]},{"cell_type":"markdown","metadata":{"id":"XOEmJEBlxPG8","colab_type":"text"},"source":["### 2. Build a DNN "]},{"cell_type":"code","metadata":{"id":"jVtpQpS6QoDq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":941},"executionInfo":{"status":"ok","timestamp":1598580084965,"user_tz":420,"elapsed":43912,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"0701f914-7822-4064-e4c9-c30e2e49a4cb"},"source":["# evaluate algorithm with DNN with 5 hidden layers and 10 epoch\n","n_folds = 5\n","l_rate = 0.001\n","n_epoch = 10\n","n_hidden = 5\n","scores = evaluate_algorithm(data_nor, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n","print('Scores: %s' % scores)\n","print('Mean Accuracy: %.3f%%' % (sum(scores)/(len(scores))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[">epoch=0, lrate=0.0010, error=970.241\n",">epoch=1, lrate=0.0010, error=746.285\n",">epoch=2, lrate=0.0010, error=440.382\n",">epoch=3, lrate=0.0010, error=266.251\n",">epoch=4, lrate=0.0010, error=204.126\n",">epoch=5, lrate=0.0010, error=179.457\n",">epoch=6, lrate=0.0010, error=167.528\n",">epoch=7, lrate=0.0010, error=160.862\n",">epoch=8, lrate=0.0010, error=156.744\n",">epoch=9, lrate=0.0010, error=154.012\n",">epoch=0, lrate=0.0010, error=1180.322\n",">epoch=1, lrate=0.0010, error=1165.283\n",">epoch=2, lrate=0.0010, error=1142.359\n",">epoch=3, lrate=0.0010, error=1104.029\n",">epoch=4, lrate=0.0010, error=1031.324\n",">epoch=5, lrate=0.0010, error=875.197\n",">epoch=6, lrate=0.0010, error=587.900\n",">epoch=7, lrate=0.0010, error=336.957\n",">epoch=8, lrate=0.0010, error=234.506\n",">epoch=9, lrate=0.0010, error=197.292\n",">epoch=0, lrate=0.0010, error=1114.095\n",">epoch=1, lrate=0.0010, error=1053.765\n",">epoch=2, lrate=0.0010, error=928.047\n",">epoch=3, lrate=0.0010, error=675.901\n",">epoch=4, lrate=0.0010, error=398.061\n",">epoch=5, lrate=0.0010, error=265.760\n",">epoch=6, lrate=0.0010, error=218.737\n",">epoch=7, lrate=0.0010, error=199.191\n",">epoch=8, lrate=0.0010, error=189.436\n",">epoch=9, lrate=0.0010, error=183.886\n",">epoch=0, lrate=0.0010, error=809.469\n",">epoch=1, lrate=0.0010, error=506.076\n",">epoch=2, lrate=0.0010, error=300.685\n",">epoch=3, lrate=0.0010, error=224.862\n",">epoch=4, lrate=0.0010, error=196.061\n",">epoch=5, lrate=0.0010, error=182.693\n",">epoch=6, lrate=0.0010, error=175.442\n",">epoch=7, lrate=0.0010, error=171.061\n",">epoch=8, lrate=0.0010, error=168.202\n",">epoch=9, lrate=0.0010, error=166.229\n",">epoch=0, lrate=0.0010, error=1159.333\n",">epoch=1, lrate=0.0010, error=1132.957\n",">epoch=2, lrate=0.0010, error=1087.346\n",">epoch=3, lrate=0.0010, error=997.122\n",">epoch=4, lrate=0.0010, error=802.109\n",">epoch=5, lrate=0.0010, error=497.720\n",">epoch=6, lrate=0.0010, error=294.188\n",">epoch=7, lrate=0.0010, error=219.322\n",">epoch=8, lrate=0.0010, error=190.796\n",">epoch=9, lrate=0.0010, error=177.511\n","Scores: [91.3738019169329, 92.97124600638978, 96.1661341853035, 93.29073482428115, 92.97124600638978]\n","Mean Accuracy: 93.355%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L3x9KYGfSAs5","colab_type":"text"},"source":["In this 5 hidden layer neural neworks, has high mean accuracy to be 93.35%."]},{"cell_type":"markdown","metadata":{"id":"9gKTsszOTDvq","colab_type":"text"},"source":["### 3.Build a RNN model"]},{"cell_type":"code","metadata":{"id":"HZbUy6ODR7vs","colab_type":"code","colab":{}},"source":["import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIK-Ko7CW8W0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1598577771178,"user_tz":420,"elapsed":115647,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"fccc86e9-8cf8-4764-f43c-dbabe8045603"},"source":["print('# of Training Samples: {}'.format(len(X_res)))\n","print('# of Test Samples: {}'.format(len(X_test)))\n","\n","num_classes = max(y_res) + 1\n","print('# of Classes: {}'.format(num_classes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# of Training Samples: 2184\n","# of Test Samples: 392\n","# of Classes: 2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUTGRYaibOrb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598577771180,"user_tz":420,"elapsed":115641,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"b79b37f5-d089-400b-c780-300555b6906f"},"source":["print(X_res.shape)\n","print(y_res.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2184, 589)\n","(2184,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f7G0f58cXFNr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1598578249073,"user_tz":420,"elapsed":593528,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"ea6ee095-8306-4df1-8419-74d8e7d52404"},"source":["#construct model\n","import tensorflow as tf\n","from tensorflow import keras\n","# Construct our model\n","in_length = 589\n","model = tf.keras.Sequential()\n","model.add(keras.layers.Embedding(10000, 32, input_length= in_length))\n","model.add(keras.layers.LSTM(64,activation=\"tanh\")) #with one LSTM layer\n","model.add(keras.layers.Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","model.fit(X_res, y_res, validation_split=0.2, epochs=3, batch_size=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 589, 32)           320000    \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 64)                24832     \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 65        \n","=================================================================\n","Total params: 344,897\n","Trainable params: 344,897\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/3\n","583/583 [==============================] - 157s 269ms/step - loss: 0.6672 - accuracy: 0.6251 - val_loss: 0.9197 - val_accuracy: 0.0000e+00\n","Epoch 2/3\n","583/583 [==============================] - 160s 274ms/step - loss: 0.6638 - accuracy: 0.6251 - val_loss: 1.0310 - val_accuracy: 0.0000e+00\n","Epoch 3/3\n","583/583 [==============================] - 158s 271ms/step - loss: 0.6625 - accuracy: 0.6251 - val_loss: 1.0967 - val_accuracy: 0.0000e+00\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f25884564e0>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"8NNJphPAc-2T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598578250508,"user_tz":420,"elapsed":594957,"user":{"displayName":"Zhuoyu Peng","photoUrl":"","userId":"15044477436634585585"}},"outputId":"50b912e9-466d-46bf-8269-d99e2dca5cea"},"source":["# Evaluate model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy: 94.64%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mI1NFiWuxfE1","colab_type":"text"},"source":["#### Summarize your findings with examples.  Explain what the manufacturer should focus on to optimize the diaper manufacturing process.\n","\n","1. All models, simple neural networks, DNN and RNN, have very good performance with high accuracy. Among them, RNN has the highest accuracy with one LSTM layer.\n","2. I used LSTM, a type of RNN, is capable of learning order depence in sequence prediction problems. In this work, we found that LSTM gives the best model, suggesting that the order the sensor detections matter. \n","\n","To optimize the diaper manufacturing process, we can print out the prediction for every a hundred sensors. If it is a bad diaper, we can give up that diaper for the rest of sensor detections since LSTM predicts well on sequencing data. "]},{"cell_type":"markdown","metadata":{"id":"23BTPFRD4ZVJ","colab_type":"text"},"source":["### Feedback\n","Neural network is the most challenging part in this course. Tuning hyperparameters is tricky, and don't which directions I should go. Neural network gives good predictions though. \n","1. In this work, I didn't use timestamp for trainning. How do I include timestamp in neural network?\n"]}]}